/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./plugin_message_handling.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./driver.js":
/*!*******************!*\
  !*** ./driver.js ***!
  \*******************/
/*! exports provided: _register, process */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"_register\", function() { return _register; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"process\", function() { return process; });\n/* harmony import */ var validation__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! validation */ \"./validation.js\");\n/* harmony import */ var exceptions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! exceptions */ \"./exceptions.js\");\n/* harmony import */ var transform_functions_RegexExtraction__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! transform_functions/RegexExtraction */ \"./transform_functions/RegexExtraction.js\");\n\n\n\nconst _register = transformFunctionClass => {\n  // check that isValid and transform functions have been defined\n  if (typeof transformFunctionClass.prototype.checkValid === 'undefined') {\n    const errorMessage = 'checkValid function not implemented';\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"RegisterError\"](errorMessage);\n  }\n\n  if (typeof transformFunctionClass.prototype.transform === 'undefined') {\n    const errorMessage = 'transform function not implemented';\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"RegisterError\"](errorMessage);\n  } // check that functionName has been assigned\n\n\n  if (transformFunctionClass.functionName === undefined) {\n    const errorMessage = 'functionName not set';\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"RegisterError\"](errorMessage);\n  } // check that configAttributes have been assigned\n\n\n  if (transformFunctionClass.configAttributes === undefined) {\n    const errorMessage = 'configAttributes not set';\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"RegisterError\"](errorMessage);\n  }\n\n  return transformFunctionClass;\n}; // TODO needs test. We weren't able to test due to issues with Jest\n\nconst process = (config, platformMetadata, scrapedData) => {\n  const functionClasses = {\n    'RegexExtraction': transform_functions_RegexExtraction__WEBPACK_IMPORTED_MODULE_2__[\"default\"]\n  };\n  const chosenFunction = functionClasses[config.type];\n\n  if (chosenFunction === undefined) {\n    const errorMessage = 'Transform function doesn\\'t exist';\n    const error = {\n      'Transform function doesn\\'t exist': config.type\n    };\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"ProcessError\"](errorMessage, error);\n  }\n\n  const FunctionClass = _register(chosenFunction); // check all attributes are present\n\n\n  const missingAttributes = Object(validation__WEBPACK_IMPORTED_MODULE_0__[\"checkAttributes\"])(FunctionClass.configAttributes, config);\n\n  if (missingAttributes.length !== 0) {\n    const errorMessage = 'Missing attributes';\n    const error = {\n      'Missing Attributes': missingAttributes\n    };\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"ProcessError\"](errorMessage, error);\n  } // check if input is an array\n\n\n  const rawInput = scrapedData[config.sourceField];\n  const isArray = Array.isArray(rawInput);\n  const inputs = isArray ? rawInput : [rawInput];\n  const results = [];\n\n  for (var input of inputs) {\n    // instantiate transform function\n    const functionInstance = new FunctionClass(config, platformMetadata); // call is valid\n\n    const isValid = functionInstance.checkValid();\n\n    if (!isValid) {\n      const errorMessage = 'Validation';\n      const error = {\n        'Validation': functionInstance.errors\n      };\n      throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"ProcessError\"](errorMessage, error);\n    } // apply transform\n\n\n    try {\n      results.push(functionInstance.transform(input));\n    } catch (err) {\n      const errorMessage = 'Transform';\n      const error = {\n        'Transform': err.message\n      };\n      throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"ProcessError\"](errorMessage, error);\n    }\n  }\n\n  if (isArray) {\n    return results;\n  } else {\n    return results[0];\n  }\n};\n\n//# sourceURL=webpack:///./driver.js?");

/***/ }),

/***/ "./exceptions.js":
/*!***********************!*\
  !*** ./exceptions.js ***!
  \***********************/
/*! exports provided: ValidationError, TransformError, ProcessError, RegisterError */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ValidationError\", function() { return ValidationError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"TransformError\", function() { return TransformError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ProcessError\", function() { return ProcessError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"RegisterError\", function() { return RegisterError; });\nclass ValidationError extends Error {\n  constructor(message) {\n    super(message);\n    this.name = 'ValidationError';\n  }\n\n}\n\nclass TransformError extends Error {\n  constructor(message) {\n    super(message);\n    this.name = 'TransformError';\n  }\n\n}\n\nclass ProcessError extends Error {\n  constructor(message, error) {\n    super(message);\n    this.name = 'ProcessorError';\n    this.error = error;\n  }\n\n}\n\nclass RegisterError extends Error {\n  constructor(message, error) {\n    super(message);\n    this.name = 'RegisterError';\n  }\n\n}\n\n\n\n//# sourceURL=webpack:///./exceptions.js?");

/***/ }),

/***/ "./plugin_message_handling.js":
/*!************************************!*\
  !*** ./plugin_message_handling.js ***!
  \************************************/
/*! exports provided: addToBrowser */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"addToBrowser\", function() { return addToBrowser; });\n/* harmony import */ var _scraping_interface_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./scraping_interface.js */ \"./scraping_interface.js\");\n\nfunction addToBrowser() {\n  if (window.hasPluginHandling) {\n    console.log('pluginMessageHandling loaded already, exiting');\n    return;\n  }\n\n  window.hasPluginHandling = true;\n\n  try {\n    browser.runtime.onMessage.addListener(message => _scraping_interface_js__WEBPACK_IMPORTED_MODULE_0__[\"parsePluginMessage\"](message));\n  } catch (err) {\n    console.log('Attaching plugin_message_handling event listener failed, ignore this message if unit testing');\n  }\n}\naddToBrowser();\n\n//# sourceURL=webpack:///./plugin_message_handling.js?");

/***/ }),

/***/ "./processor_functions.js":
/*!********************************!*\
  !*** ./processor_functions.js ***!
  \********************************/
/*! exports provided: processPrice, cleanText, extractNumbers */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"processPrice\", function() { return processPrice; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"cleanText\", function() { return cleanText; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractNumbers\", function() { return extractNumbers; });\n/**\n* Processing functions used by the scraper\n*/\nfunction processPrice(rawPrice) {\n  const initialCleaningRegex = /[^\\d\\s.,]/g;\n  var cleanedPrice = rawPrice.replace(initialCleaningRegex, '').trim();\n  var lastPos = cleanedPrice.length - 1;\n\n  while (isNaN(parseInt(cleanedPrice.charAt(lastPos))) && lastPos > 0) {\n    lastPos--;\n  }\n\n  const delimeterPosition = lastPos - 2;\n\n  if (new Set(['.', ',', ' ']).has(cleanedPrice.charAt(delimeterPosition))) {\n    var integerPart = cleanedPrice.substr(0, delimeterPosition);\n    var decimalPart = cleanedPrice.substr(delimeterPosition, cleanedPrice.length);\n    var cleanedIntegerPart = integerPart.replace(/\\D/g, '');\n    var cleanedDecimalPart = decimalPart.replace(/\\D/g, '');\n    return `${cleanedIntegerPart}.${cleanedDecimalPart}`;\n  } else {\n    return cleanedPrice.replace(/\\D/g, '');\n  }\n}\n/**\n *  Trim leading and trailing whitespace. Remove unnecessary newlines  within the string\n */\n\nfunction cleanText(str) {\n  const twoOrMoreNewlines = /\\n\\n+/g;\n  return str.trim().replace(twoOrMoreNewlines, '\\n\\n');\n}\nfunction extractNumbers(str) {\n  return str.replace(/\\D+/g, '');\n}\n\n//# sourceURL=webpack:///./processor_functions.js?");

/***/ }),

/***/ "./scrape_actions/NumbersOnlyPagination.js":
/*!*************************************************!*\
  !*** ./scrape_actions/NumbersOnlyPagination.js ***!
  \*************************************************/
/*! exports provided: NumbersOnlyPagination */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NumbersOnlyPagination\", function() { return NumbersOnlyPagination; });\n/* harmony import */ var scrape_actions_ScrapeAction__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! scrape_actions/ScrapeAction */ \"./scrape_actions/ScrapeAction.js\");\n/* harmony import */ var utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! utils */ \"./utils.js\");\n/* harmony import */ var scraping__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! scraping */ \"./scraping.js\");\n\n\n\nclass NumbersOnlyPagination extends scrape_actions_ScrapeAction__WEBPACK_IMPORTED_MODULE_0__[\"ScrapeAction\"] {\n  constructor(config) {\n    console.log('Instantiating NumbersOnlyPagination');\n    super();\n    this.setupFields = this.setupFields.bind(this);\n    this.getNumberElements = this.getNumberElements.bind(this);\n    this.waitForAndScrapeNewUrls = this.waitForAndScrapeNewUrls.bind(this);\n    this.clickThroughAndScrape = this.clickThroughAndScrape.bind(this);\n    this.scrape = this.scrape.bind(this);\n    this.setupFields(config);\n    console.log('Validation complete');\n  }\n\n  setupFields(config) {\n    this.itemsContainerXpath = this.validateXpath(config.itemsContainerXpath);\n    this.itemRegex = this.validateRegex(config.itemRegex);\n    this.numbersElementXpath = this.validateXpath(config.numbersElementXpath);\n  }\n\n  getNumberElements(numberElementXpath) {\n    console.log('Getting number elements');\n    return Object(utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementsByXpath\"])(numberElementXpath);\n  }\n\n  async waitForAndScrapeNewUrls(itemsContainer, itemRegex, previousUrls) {\n    let itemUrls = await Object(scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"])(itemsContainer, itemRegex, false);\n    let timeoutCount = 0;\n\n    while ((Object(utils__WEBPACK_IMPORTED_MODULE_1__[\"intersection\"])(previousUrls, itemUrls).length > 0 || itemUrls.length === 0) && timeoutCount < 10) {\n      console.log('Waiting for new URLs...');\n      await Object(utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"])(1000);\n      itemUrls = await Object(scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"])(itemsContainer, itemRegex, false);\n      timeoutCount += 1;\n    }\n\n    return Promise.resolve(itemUrls);\n  }\n\n  async clickThroughAndScrape(numberElements, itemsContainer, itemRegex) {\n    const allItemUrls = [];\n    var previousUrls = [];\n\n    for (let element of numberElements) {\n      console.log('Clicking number element');\n      element.click();\n      let itemUrls = await this.waitForAndScrapeNewUrls(itemsContainer, itemRegex, previousUrls);\n      previousUrls = [];\n      console.log(`Found ${itemUrls.length} urls on this page`);\n      itemUrls.map(element => {\n        allItemUrls.push(element);\n        previousUrls.push(element);\n      });\n    }\n\n    return Promise.resolve(allItemUrls);\n  }\n\n  async scrape() {\n    try {\n      console.log('Scrape starting');\n      const numberElements = await this.getNumberElements(this.numbersElementXpath);\n      const itemsContainer = Object(utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"])(this.itemsContainerXpath);\n      const urls = await this.clickThroughAndScrape(numberElements, itemsContainer, this.itemRegex);\n      console.log('Finished clickThroughAndScrape');\n      const uniqueUrls = Object(utils__WEBPACK_IMPORTED_MODULE_1__[\"removeDuplicates\"])(urls);\n      console.log(`numbersOnlyPagination has found ${uniqueUrls.length} URLs`);\n      return Promise.resolve(uniqueUrls);\n    } catch (err) {\n      console.log(err);\n    }\n  }\n\n}\n\n//# sourceURL=webpack:///./scrape_actions/NumbersOnlyPagination.js?");

/***/ }),

/***/ "./scrape_actions/ScrapeAction.js":
/*!****************************************!*\
  !*** ./scrape_actions/ScrapeAction.js ***!
  \****************************************/
/*! exports provided: ScrapeAction */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ScrapeAction\", function() { return ScrapeAction; });\n/* harmony import */ var utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! utils */ \"./utils.js\");\n\nclass ScrapeAction {\n  constructor() {\n    if (this.constructor === ScrapeAction) {\n      throw new Error('Scrape Action should not be insantiated');\n    }\n  }\n\n  validateXpath(xpath) {\n    // Test if the element is on the page.\n    const container = Object(utils__WEBPACK_IMPORTED_MODULE_0__[\"getElementByXpath\"])(xpath);\n\n    if (!container) {\n      console.log(`ScrapeAction: Unable to find container element with xpath ${xpath}`);\n      xpath = null;\n    }\n\n    return xpath;\n  }\n\n  validateRegex(regex) {\n    try {\n      regex = RegExp(regex, 'g');\n    } catch (err) {\n      console.log(\"ScrapeAction: regex isn't a valid regular expression\");\n      regex = null;\n    }\n\n    return regex;\n  }\n\n}\n\n//# sourceURL=webpack:///./scrape_actions/ScrapeAction.js?");

/***/ }),

/***/ "./scraping.js":
/*!*********************!*\
  !*** ./scraping.js ***!
  \*********************/
/*! exports provided: scrape, sortFields, scrapePage, processData, validateItem, validatePage, waitForMoreUrls, scrollAndScrape, loadContentAndScroll, clickGalleryExtract, extractContainedImages, navigate, processUrls, getAndProcessUrlsFromElement, moveToNextPage, waitForFirstChange, waitForChangesToStop, nextPageAndScrapeUrls, pagination, xpathDataExtraction, extractUrlsWithRegex, regexUrlExtraction, regexUrlProcessor, extractString, clickRegexExtractStringReplace, simpleImageExtraction, validateRegexDataExtraction, regexDataExtraction, staticValue, click, attemptLogin */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrape\", function() { return scrape; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sortFields\", function() { return sortFields; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrapePage\", function() { return scrapePage; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"processData\", function() { return processData; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateItem\", function() { return validateItem; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validatePage\", function() { return validatePage; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"waitForMoreUrls\", function() { return waitForMoreUrls; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrollAndScrape\", function() { return scrollAndScrape; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"loadContentAndScroll\", function() { return loadContentAndScroll; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"clickGalleryExtract\", function() { return clickGalleryExtract; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractContainedImages\", function() { return extractContainedImages; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"navigate\", function() { return navigate; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"processUrls\", function() { return processUrls; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getAndProcessUrlsFromElement\", function() { return getAndProcessUrlsFromElement; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"moveToNextPage\", function() { return moveToNextPage; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"waitForFirstChange\", function() { return waitForFirstChange; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"waitForChangesToStop\", function() { return waitForChangesToStop; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"nextPageAndScrapeUrls\", function() { return nextPageAndScrapeUrls; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pagination\", function() { return pagination; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"xpathDataExtraction\", function() { return xpathDataExtraction; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractUrlsWithRegex\", function() { return extractUrlsWithRegex; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"regexUrlExtraction\", function() { return regexUrlExtraction; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"regexUrlProcessor\", function() { return regexUrlProcessor; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"extractString\", function() { return extractString; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"clickRegexExtractStringReplace\", function() { return clickRegexExtractStringReplace; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"simpleImageExtraction\", function() { return simpleImageExtraction; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateRegexDataExtraction\", function() { return validateRegexDataExtraction; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"regexDataExtraction\", function() { return regexDataExtraction; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"staticValue\", function() { return staticValue; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"click\", function() { return click; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"attemptLogin\", function() { return attemptLogin; });\n/* harmony import */ var _processor_functions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./processor_functions */ \"./processor_functions.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ \"./utils.js\");\n/* harmony import */ var _scraping__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./scraping */ \"./scraping.js\");\n/* harmony import */ var scrape_actions_NumbersOnlyPagination__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! scrape_actions/NumbersOnlyPagination */ \"./scrape_actions/NumbersOnlyPagination.js\");\n/* harmony import */ var driver__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! driver */ \"./driver.js\");\n/**\n* code used for scraping\n*/\n\n\n\n\n\n/**\n* This method takes the json representing a scrape configuration and runs the\n* scrape.\n*/\n\nconst scrape = async function (fieldConfig, platformMetadata) {\n  // declare variables used in more than one case\n  var containerXpath, regex, group, removeDuplicates;\n\n  switch (fieldConfig.type) {\n    case 'ClickGalleryExtract':\n      var {\n        galleryXpath,\n        imageXpath,\n        waitTime\n      } = fieldConfig;\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"clickGalleryExtract\"](galleryXpath, imageXpath, waitTime);\n\n    case 'ExtractContainedImages':\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractContainedImages\"](fieldConfig);\n\n    case 'XpathDataExtraction':\n      var {\n        elementXpath,\n        contentType,\n        targetAttribute,\n        processor\n      } = fieldConfig;\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"xpathDataExtraction\"](elementXpath, contentType, targetAttribute, processor);\n\n    case 'RegexUrlExtraction':\n      var infiniteScroll;\n      ({\n        containerXpath,\n        regex,\n        infiniteScroll\n      } = fieldConfig);\n      var maxIndexPages = platformMetadata.max_index_pages;\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"regexUrlExtraction\"](containerXpath, regex, infiniteScroll, maxIndexPages);\n\n    case 'RegexUrlProcessor':\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"regexUrlProcessor\"](fieldConfig.regex);\n\n    case 'ClickRegexExtractStringReplace':\n      var buttonXpath, replaceSource, replaceTarget;\n      ({\n        buttonXpath,\n        containerXpath,\n        regex,\n        group,\n        replaceSource,\n        replaceTarget,\n        removeDuplicates\n      } = fieldConfig);\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"clickRegexExtractStringReplace\"](buttonXpath, containerXpath, regex, group, replaceSource, replaceTarget, removeDuplicates);\n\n    case 'SimpleImageExtraction':\n      ({\n        containerXpath,\n        regex\n      } = fieldConfig);\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"simpleImageExtraction\"](containerXpath, regex);\n\n    case 'RegexDataExtraction':\n      var matchNumber;\n      ({\n        regex,\n        matchNumber,\n        group,\n        containerXpath,\n        removeDuplicates\n      } = fieldConfig);\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"regexDataExtraction\"](regex, matchNumber, group, containerXpath, removeDuplicates);\n\n    case 'LoadContentAndScroll':\n      var loadButtonXpath;\n      ({\n        loadButtonXpath,\n        containerXpath,\n        regex\n      } = fieldConfig);\n      const scrollCount = platformMetadata['max_index_pages'];\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"loadContentAndScroll\"](loadButtonXpath, containerXpath, regex, scrollCount);\n\n    case 'StaticValue':\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"staticValue\"](fieldConfig.staticValue);\n\n    case 'Click':\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"click\"](fieldConfig.xpath);\n\n    case 'Wait':\n      return _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](fieldConfig.wait);\n\n    case 'NumbersOnlyPagination':\n      const numbersOnlyPaginationAction = new scrape_actions_NumbersOnlyPagination__WEBPACK_IMPORTED_MODULE_3__[\"NumbersOnlyPagination\"](fieldConfig);\n      const result = await numbersOnlyPaginationAction.scrape();\n      return result;\n\n    case 'Pagination':\n      var xpathOfNextButton;\n      var urlRegex;\n      var formatString;\n      ({\n        containerXpath,\n        xpathOfNextButton,\n        urlRegex,\n        formatString\n      } = fieldConfig);\n      return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"pagination\"](platformMetadata.max_index_pages, containerXpath, formatString, urlRegex, xpathOfNextButton);\n\n    default:\n      console.log(`Unrecognised scrape action: ${fieldConfig.type}`);\n      throw _utils__WEBPACK_IMPORTED_MODULE_1__[\"scrapeError\"]('Unrecognised scrape action');\n  }\n};\n/**\n *  This function takes an item scrape object and returns the keys as an array\n *  in the order assigned to them in the config. This array is then used to\n *  populate the item scrapes in the correct order in reloadConfiguration.\n */\n\nconst sortFields = fields => {\n  const sortFunction = (a, b) => {\n    if (!('order' in fields[a])) {\n      return Number.MAX_SAFE_INTEGER;\n    } else if (!('order' in fields[b])) {\n      return Number.MIN_SAFE_INTEGER;\n    } else {\n      return fields[a].order - fields[b].order;\n    }\n  };\n\n  var fieldKeys = Object.keys(fields);\n  fieldKeys.sort(sortFunction);\n  return fieldKeys;\n};\nconst scrapePage = function (pageConfig, platformMetadata) {\n  return new Promise(async function (resolve, reject) {\n    var results = {}; // sort fields so they run in the correct order\n\n    var fieldKeys = sortFields(pageConfig);\n\n    for (var fieldKey of fieldKeys) {\n      try {\n        results[fieldKey] = await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"scrape\"](pageConfig[fieldKey], platformMetadata);\n      } catch (err) {\n        console.log('scrapePage error ' + err);\n        results[fieldKey] = undefined;\n      }\n    }\n\n    console.log('scrapePage function has found ' + JSON.stringify(results));\n    resolve(results);\n  });\n};\nconst processData = function (scrapedData, transformConfig, platformMetadata) {\n  // sort fields so they run in the correct order\n  var fieldKeys = sortFields(transformConfig);\n\n  for (var fieldKey of fieldKeys) {\n    try {\n      var fieldConfig = transformConfig[fieldKey];\n      scrapedData[fieldKey] = Object(driver__WEBPACK_IMPORTED_MODULE_4__[\"process\"])(fieldConfig, platformMetadata, scrapedData);\n    } catch (err) {\n      // TODO handle errors differently\n      console.log('scrapePage error ' + err);\n      scrapedData[fieldKey] = undefined;\n    }\n  }\n\n  return scrapedData;\n};\nconst validateItem = async function (xpath, shouldExist, callback, timeout = 10) {\n  var element = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](xpath);\n  var count = 0; // wait for item to load\n\n  while (element === null && count < timeout) {\n    await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](1000);\n    element = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](xpath);\n    ++count;\n  }\n\n  console.log(`element is ${element}`);\n  const elementExists = element !== null && element.offsetParent !== null;\n  console.log(`element exist ${elementExists}`); // This line acts as an xor\n\n  callback(shouldExist ? elementExists : !elementExists);\n};\nconst validatePage = async function (validationCommands) {\n  return new Promise(resolve => {\n    var counter = 0;\n    var abort = false;\n\n    for (var validationCommand of validationCommands) {\n      var {\n        xpath,\n        shouldExist\n      } = validationCommand;\n      _scraping__WEBPACK_IMPORTED_MODULE_2__[\"validateItem\"](xpath, shouldExist, function (result) {\n        if (abort) {\n          return;\n        }\n\n        if (!result) {\n          abort = true;\n          resolve(false);\n        } else {\n          ++counter;\n\n          if (counter === validationCommands.length) {\n            abort = true;\n            resolve(true);\n          }\n        }\n      });\n    }\n  });\n};\nconst waitForMoreUrls = async function (urlsCount, container, regex) {\n  // Helper function for scrollAndScrape\n  var currentUrlsLength = urlsCount;\n  const maxAttempts = 10;\n\n  for (var j = 0; j < maxAttempts; ++j) {\n    var newUrlsCount = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"](container, regex).length;\n\n    if (newUrlsCount > currentUrlsLength) {\n      console.log('Found more urls!');\n      break;\n    } else {\n      console.log('Polling for more urls...');\n      await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](1000);\n    }\n  }\n\n  return newUrlsCount;\n};\nconst scrollAndScrape = async function (initialUrlCount, container, regex, scrollCount, loadButtonXpath = undefined) {\n  /*\n    Takes an initial URL count and scrolls down the page iteratively, checking if the number of URLs scraped increases\n    as it goes. Once the increases stop, the for loops are broken out of, or they reach the end of their counts naturally,\n    at which all URLs on the page are scraped and returned.\n  */\n  var urlCount = initialUrlCount;\n\n  for (var i = 0; i < scrollCount; ++i) {\n    console.log(`URL count is ${urlCount}, scroll iteration ${i} starting...`); // 1. scroll to bottom of the page\n\n    _utils__WEBPACK_IMPORTED_MODULE_1__[\"scrollToBottom\"](); // 2. click the next button\n\n    if (loadButtonXpath) {\n      // break if loadButtonXpath is defined but the button isn't present\n      var noLoadMoreButton = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](loadButtonXpath) === null;\n      if (noLoadMoreButton) break;\n\n      try {\n        _utils__WEBPACK_IMPORTED_MODULE_1__[\"clickElement\"](loadButtonXpath);\n        console.log('Load button clicked...');\n      } catch (err) {\n        console.log('Button not clicked, continuing in case the scrape is OK');\n      }\n    } // 3. wait for urls to finish loading\n\n\n    var oldUrlCount = urlCount;\n    urlCount = await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"waitForMoreUrls\"](urlCount, container, regex); // 4. check if we should stop because no more urls have loaded\n\n    var noNewUrls = urlCount === oldUrlCount;\n    if (noNewUrls) break;\n  }\n\n  const allUrls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"](container, regex);\n  const uniqueUrls = _utils__WEBPACK_IMPORTED_MODULE_1__[\"removeDuplicates\"](allUrls);\n  console.log(`loadContentAndScroll found ${uniqueUrls.length} unique URLs`);\n  return Promise.resolve(uniqueUrls);\n};\nconst loadContentAndScroll = async function (loadButtonXpath, containerXpath, regex, scrollCount = 5) {\n  _utils__WEBPACK_IMPORTED_MODULE_1__[\"logFunctionCall\"](loadContentAndScroll, arguments);\n\n  if (!containerXpath) {\n    containerXpath = '//body';\n    console.log(`Defaulting containerXpath to ${containerXpath}`);\n  }\n\n  if (!regex) {\n    regex = '.*';\n    console.log(`Defaulting regex to ${regex}`);\n  } // We don't check that the element pointed to by loadButtonXpath exists\n  // because it may not exist if there is less than one page worth of results\n  // validation\n\n\n  if (_utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath) === null) return Promise.resolve([]); // validation\n\n  try {\n    RegExp(regex);\n  } catch (err) {\n    console.log('loadContentAndScroll: Handed invalid regex. Returning...');\n    return Promise.resolve([]);\n  }\n\n  try {\n    const container = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath);\n    const initialUrlCount = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"](container, regex).length;\n    const result = await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"scrollAndScrape\"](initialUrlCount, container, regex, scrollCount, loadButtonXpath);\n    return Promise.resolve(result);\n  } catch (err) {\n    console.log(`Error in loadContentAndScroll: ${err}`);\n    return Promise.resolve([]);\n  }\n};\nconst clickGalleryExtract = async function (galleryXpath, imageXpath, waitTime) {\n  const childExtract = async function (element) {\n    var sources = [];\n    element.click();\n    await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](waitTime);\n    const image = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](imageXpath);\n\n    if (image) {\n      let source = image.getAttribute('src');\n      if (source) sources.push(source); // source may be null\n    }\n\n    for (var child of element.children) {\n      let childSources = await childExtract(child);\n      sources.push(...childSources);\n    }\n\n    return sources;\n  };\n\n  const gallery = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](galleryXpath);\n\n  if (!gallery) {\n    console.log(`clickGalleryExtract: Could not find gallery element with xpath ${galleryXpath}`);\n    return [];\n  }\n\n  const waitTimeIsInt = !isNaN(parseInt(waitTime));\n\n  if (!waitTimeIsInt) {\n    console.log(`clickGalleryExtract: wait time \"${waitTime}\" is not parseable as int`);\n    return [];\n  }\n\n  const allSources = await childExtract(gallery);\n  return _utils__WEBPACK_IMPORTED_MODULE_1__[\"removeDuplicates\"](allSources);\n};\nconst extractContainedImages = function (payload) {\n  const container = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](payload.containerXpath);\n  return _utils__WEBPACK_IMPORTED_MODULE_1__[\"getAttributeRecursively\"](container, 'src');\n};\nconst navigate = function (containerXpath, templateUrl, nextButtonXpath) {\n  // This function needs refactoring to use maxIndex, and needs to be unit tested after refactoring.\n  console.log('Navigation starting');\n  var maxResults = 100;\n  var urls = new Set();\n  const containerElement = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath);\n\n  const addUrls = function (newUrls) {\n    for (var newUrl of newUrls) {\n      if (urls.size < maxResults) {\n        if (_utils__WEBPACK_IMPORTED_MODULE_1__[\"checkStringContainsTemplate\"](newUrl, templateUrl)) {\n          urls.add(newUrl);\n        }\n      } else {\n        return false;\n      }\n    }\n\n    return true;\n  };\n\n  return new Promise(resolve => {\n    var intervalId = setInterval(function () {\n      if (!addUrls(_utils__WEBPACK_IMPORTED_MODULE_1__[\"getAttributeRecursively\"](containerElement, 'href'))) {\n        clearInterval(intervalId);\n        console.log(urls);\n        resolve(urls);\n      }\n\n      _utils__WEBPACK_IMPORTED_MODULE_1__[\"clickElement\"](nextButtonXpath);\n    }, 500);\n  });\n};\nconst processUrls = function (urls, urlRegexString) {\n  /**\n  * simplify, filter and deduplicate urls\n  */\n  console.log('Received ' + urls.length + ' urls');\n  return Array.from(new Set(urls.map(url => _utils__WEBPACK_IMPORTED_MODULE_1__[\"simplifyUrl\"](url)).filter(url => _utils__WEBPACK_IMPORTED_MODULE_1__[\"filterUrl\"](url, urlRegexString))));\n};\nconst getAndProcessUrlsFromElement = function (element, urlRegexString) {\n  const urlsToProcess = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getAttributeRecursively\"](element, 'href');\n  return _scraping__WEBPACK_IMPORTED_MODULE_2__[\"processUrls\"](urlsToProcess, urlRegexString);\n};\nconst moveToNextPage = function (nextButtonIdentifier, pageNum, xpathOfNextButton) {\n  // click next\n  try {\n    var nextButtonContainer = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](xpathOfNextButton);\n    console.log('Moving to next page...');\n    console.log(`${nextButtonContainer} is the next button container`);\n    nextButtonContainer.click();\n  } catch (err) {\n    console.log('Next page error');\n  }\n};\nconst waitForFirstChange = async function (tempUrls, firstChangeWaitIncrement, firstChangeWaitTimeout, container, urlRegexString, urlsInCommon) {\n  // wait for a change\n  for (var i = 0; i < firstChangeWaitIncrement; ++i) {\n    console.log('Waiting for change...');\n    await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](firstChangeWaitTimeout);\n    let newUrls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"getAndProcessUrlsFromElement\"](container, urlRegexString);\n    let newUrlsInCommon = _utils__WEBPACK_IMPORTED_MODULE_1__[\"intersection\"](newUrls, tempUrls).length;\n\n    if (urlsInCommon !== newUrlsInCommon) {\n      return newUrls;\n    }\n  } // for loop completed without a url change, therefore no new urls\n\n\n  throw _utils__WEBPACK_IMPORTED_MODULE_1__[\"scrapeError\"]('Loop completed without a URL change');\n};\nconst waitForChangesToStop = async function (tempUrls, stabaliseWaitIncrement, stabaliseWaitTimeout, container, urlRegexString, urlsInCommon) {\n  for (var i = 0; i < stabaliseWaitIncrement; ++i) {\n    console.log('Waiting for changes to stop...');\n    await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](stabaliseWaitTimeout);\n    let newUrls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"getAndProcessUrlsFromElement\"](container, urlRegexString);\n    let newUrlsInCommon = _utils__WEBPACK_IMPORTED_MODULE_1__[\"intersection\"](newUrls, tempUrls).length; // changes have stopped\n\n    if (urlsInCommon === newUrlsInCommon) {\n      return newUrls;\n    }\n\n    tempUrls = newUrls;\n    urlsInCommon = newUrlsInCommon;\n  }\n\n  return tempUrls;\n};\nconst nextPageAndScrapeUrls = async function (firstChangeWaitTimeout, firstChangeWaitIncrement, stabaliseWaitTimeout, stabaliseWaitIncrement, container, pageNum, nextButtonIdentifier, urlRegexString, xpathOfNextButton) {\n  /**\n  * First, wait until there is a change in the urls, if there is one.\n  * Second, once there's been a change, wait until changes stop\n  *\n  * firstChangeWaitTimeout: Timeout for initially waiting for the urls to change\n  * firstChangeWaitIncrement: How long to wait between checking if urls had changed\n  * stabaliseWaitTimeout: Timeout for waiting for the url changes to stablise\n  * stabaliseWaitIncrement: How long to wait between checking if urls had stablised\n  */\n  // get initial urls\n  console.log('nextPageAndScrapeURLs starting...');\n\n  try {\n    var tempUrls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"getAndProcessUrlsFromElement\"](container, urlRegexString);\n  } catch (err) {\n    console.log(err);\n  }\n\n  try {\n    var urlsInCommon = _utils__WEBPACK_IMPORTED_MODULE_1__[\"intersection\"](tempUrls, tempUrls).length;\n  } catch (err) {\n    console.log(err);\n  }\n\n  try {\n    _scraping__WEBPACK_IMPORTED_MODULE_2__[\"moveToNextPage\"](nextButtonIdentifier, pageNum, xpathOfNextButton);\n  } catch (err) {\n    console.log(err);\n  }\n\n  try {\n    tempUrls = await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"waitForFirstChange\"](tempUrls, firstChangeWaitIncrement, firstChangeWaitTimeout, container, urlRegexString, urlsInCommon);\n  } catch (err) {\n    console.log(err);\n  }\n\n  try {\n    tempUrls = await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"waitForChangesToStop\"](tempUrls, stabaliseWaitIncrement, stabaliseWaitTimeout, container, urlRegexString, urlsInCommon);\n  } catch (err) {\n    console.log(err);\n  }\n\n  return tempUrls;\n};\nconst pagination = async function (numberOfPages, containerXpath, nextButtonIdentifier, urlRegexString, xpathOfNextButton) {\n  // Function needs to be refactored as part of its own ticket, and fully unit tested\n\n  /**\n    Calls functions for pagination scraping.\n  **/\n  console.log('Pagination function starting with ' + numberOfPages + ' as num of pages, ' + containerXpath + ' as the container path and ' + nextButtonIdentifier + ' as the next button regex and ' + urlRegexString + ' as the url regex ' + xpathOfNextButton + ' as xpath of next page button');\n  return new Promise(async function (resolve) {\n    // scrape first page\n    var container = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath);\n    console.log('Container found as ' + container);\n    var urls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"getAndProcessUrlsFromElement\"](container, urlRegexString);\n    console.log(urls.length + ' Initial URLs found');\n    numberOfPages--; // scrape the remaining pages\n\n    for (var i = 0; i < numberOfPages; i++) {\n      urls.push(...(await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"nextPageAndScrapeUrls\"](5000, 0.5, 5000, 0.5, container, i + 2, nextButtonIdentifier, urlRegexString, xpathOfNextButton)));\n    }\n\n    console.log('Pagination scrape has found ' + urls.length + ' URLs');\n    resolve(urls);\n  });\n};\nconst xpathDataExtraction = function (elementXpath, contentType, targetAttribute, processorFunction) {\n  _utils__WEBPACK_IMPORTED_MODULE_1__[\"logFunctionCall\"](xpathDataExtraction, arguments); // get result from page\n\n  var result;\n\n  switch (contentType) {\n    case 'TEXT':\n      result = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementTextByXpath\"](elementXpath);\n      break;\n\n    case 'ATTRIBUTE':\n      result = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getValueOfElementAttribute\"](elementXpath, targetAttribute);\n      break;\n  }\n\n  console.log(`xpathDataExtraction: Got \"${result}\" from Page. Processing...`); // apply processor function\n\n  var processedResult;\n\n  try {\n    const processor = _processor_functions__WEBPACK_IMPORTED_MODULE_0__[processorFunction];\n    processedResult = processor(result);\n    console.log(`xpathDataExtraction: Processed \"${result}\" to \"${processedResult}\"`);\n  } catch (err) {\n    console.log(`xpathDataExtraction: Error calling processor function ${processorFunction} with \"${result}\"`);\n    processedResult = result;\n  }\n\n  console.log(`xpathDataExtraction: Returning - \"${processedResult}\"`);\n  return Promise.resolve(processedResult);\n};\nconst extractUrlsWithRegex = function (container, regex) {\n  // get all urls in container\n  const allUrls = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getAttributeRecursively\"](container, 'href'); // run the regex on all the urls\n\n  var matchedUrls = [];\n\n  for (var url of allUrls) {\n    var match;\n\n    try {\n      if ((match = url.match(regex)) !== null) {\n        matchedUrls.push(match[0]);\n      }\n    } catch (err) {\n      console.log(`extractUrlsWithRegex: Exception trying to match: ${url}`);\n    }\n  }\n\n  return matchedUrls;\n};\nconst regexUrlExtraction = async function (containerXpath, regex, infiniteScroll, scrollCount = 5) {\n  _utils__WEBPACK_IMPORTED_MODULE_1__[\"logFunctionCall\"](regexUrlExtraction, arguments); // Validation: Default undefined regex to be any url\n\n  if (!regex) {\n    console.log(\"Defaulting regex to '.*' to accept any URL\");\n    regex = '.*';\n  } // Validation: get container, default to document.body if no container provided\n\n\n  const container = containerXpath ? _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath) : document.body;\n  console.log('Container found as ' + container);\n  var urls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"](container, regex);\n\n  if (infiniteScroll) {\n    for (var i = 0; i < scrollCount; ++i) {\n      // 1. If using container xpath scroll to bottom of the container, else scroll\n      // to the bottom of the page\n      if (containerXpath) {\n        let containerHeight = container.getBoundingClientRect().height;\n        _utils__WEBPACK_IMPORTED_MODULE_1__[\"scrollToHeight\"](container.offsetTop + containerHeight);\n      } else {\n        _utils__WEBPACK_IMPORTED_MODULE_1__[\"scrollToBottom\"]();\n      } // 2. wait for more urls to load\n\n\n      var currentUrlsLength = urls.length;\n      var foundMoreUrls = false;\n\n      for (var j = 0; j < 10; ++j) {\n        if ((urls = _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractUrlsWithRegex\"](container, regex)).length > currentUrlsLength) {\n          foundMoreUrls = true;\n          break;\n        }\n\n        await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](1000);\n      }\n\n      if (!foundMoreUrls) break;\n    }\n  } // dedupe the urls\n\n\n  var uniqueUrls = [...new Set(urls)];\n  console.log('RegexUrlExtraction found ' + uniqueUrls.length + ' urls');\n  return Promise.resolve(uniqueUrls);\n};\nconst regexUrlProcessor = function (regex) {\n  console.log(`Running regexUrlProcessor with regex ${regex}`); // match regex to url and return 1st group\n  // otherwise, return empty string\n\n  try {\n    const match = window.location.href.match(regex);\n    return match[1];\n  } catch (__) {\n    return '';\n  }\n};\nconst extractString = async function (maxImages, containerXpath, regexObj, groupInt, buttonXpath) {\n  var results = [];\n\n  for (var i = 0; i < maxImages; ++i) {\n    console.log('Looping'); // Get container outerHTML and extract regex matches\n\n    try {\n      var searchString = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath).outerHTML;\n    } catch (__) {\n      console.log(`clickRegexExtractStringReplace: Unable to find container element using xpath ${containerXpath}`);\n    } // extract search results and add them to overall results\n\n\n    var searchResults = _utils__WEBPACK_IMPORTED_MODULE_1__[\"globalRegexWithGroup\"](regexObj, searchString, groupInt);\n    results.push(...searchResults); // Click button to prompt next image\n\n    var button = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](buttonXpath); // finish loop if button no longer exists\n\n    if (button === null) {\n      break;\n    } // Click button to prompt next image\n\n\n    button.click(); // Wait for next image to load\n    // TODO: User should be able to enter a specific wait time.\n    // TODO: Wait time should be based on something on the page, not arbitrary time.\n\n    await _utils__WEBPACK_IMPORTED_MODULE_1__[\"sleep\"](1000);\n  }\n\n  return Promise.resolve(results);\n};\nconst clickRegexExtractStringReplace = async function (buttonXpath, containerXpath, regex, group, replaceSource, replaceTarget, removeDuplicates, maxImages = 5) {\n  // hard coded max images to 5. Should be pulled from platform metadata\n  const initialLogMessage = `clickRegexExtractStringReplace(buttonXpath=${buttonXpath}, containerXpath=${containerXpath}, regex=${regex}, group=${group} replaceSource=${replaceSource}, replaceTarget=${replaceTarget}, removeDuplicates=${removeDuplicates})`;\n  console.log(initialLogMessage); // Validation: Create regex object with g flag to find all matches\n\n  try {\n    var regexObj = RegExp(regex, 'g');\n    console.log(RegExp);\n  } catch (err) {\n    console.log(`clickRegexExtractStringReplace: Unable to create regex object from - ${regex}`);\n    console.log('returning');\n    return [];\n  } // Validation: Ensure provided regex group is valid\n\n\n  const groupInt = parseInt(group);\n\n  if (isNaN(groupInt)) {\n    console.log(`clickRegexExtractStringReplace: provided group ${group} is not a valid integer`);\n    return [];\n  } // Validation: Ensure removeDuplicates is either true or false\n\n\n  try {\n    var removeDuplicatesBool = JSON.parse(removeDuplicates);\n\n    if (!(typeof removeDuplicatesBool === 'boolean')) {\n      throw _utils__WEBPACK_IMPORTED_MODULE_1__[\"scrapeError\"]('removeDuplicates is not a boolean value');\n    }\n  } catch (__) {\n    console.log(`clickRegexExtractStringReplace: removeDuplicates value ${removeDuplicates} could not be parsed as boolean value`);\n    return [];\n  }\n\n  console.log('Calling extractString');\n  var results = await _scraping__WEBPACK_IMPORTED_MODULE_2__[\"extractString\"](maxImages, containerXpath, regexObj, groupInt, buttonXpath);\n\n  try {\n    var searchString = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath).outerHTML;\n  } catch (__) {\n    console.log(`clickRegexExtractStringReplace: Unable to find element using xpath ${containerXpath}`);\n  } // Perform the url one more time after final click\n\n\n  var searchResults = _utils__WEBPACK_IMPORTED_MODULE_1__[\"globalRegexWithGroup\"](regexObj, searchString, groupInt);\n  results.push(...searchResults); // Deduplicate results\n\n  if (removeDuplicates) {\n    results = _utils__WEBPACK_IMPORTED_MODULE_1__[\"removeDuplicates\"](results);\n  } // Once duplicates are removed we take the first maxImages items\n\n\n  const slicedResults = results.slice(0, maxImages); // Apply replacement\n\n  var replacedResults = _utils__WEBPACK_IMPORTED_MODULE_1__[\"arrayStringReplace\"](slicedResults, replaceSource, replaceTarget);\n  console.log(`clickRegexExtractStringReplace: Found ${replacedResults.length} results`);\n  return replacedResults;\n};\nconst simpleImageExtraction = function (containerXpath, regex) {\n  _utils__WEBPACK_IMPORTED_MODULE_1__[\"logFunctionCall\"](simpleImageExtraction, arguments); // Default undefined regex to be any url\n\n  if (!regex) {\n    console.log(\"Defaulting regex to '.*' to accept any URL\");\n    regex = '.*';\n  } // get container, default to document.body if no container provided\n\n\n  const container = containerXpath ? _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath) : document.body;\n  console.log('Container found as ' + container); // get all urls in container\n\n  const allUrls = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getAttributeRecursively\"](container, 'src'); // run the regex on all the urls\n\n  var matchedUrls = [];\n\n  for (var url of allUrls) {\n    var match;\n\n    if ((match = url.match(regex)) !== null) {\n      matchedUrls.push(match[0]);\n    }\n  } // dedupe the urls\n\n\n  var uniqueUrls = [...new Set(matchedUrls)];\n  console.log('simpleImageExtraction found ' + uniqueUrls.length + ' urls');\n  return Promise.resolve(uniqueUrls);\n};\nconst validateRegexDataExtraction = function (regexString, matchNumber, group, containerXpath) {\n  // regexString\n  try {\n    var regex = RegExp(regexString, 'g');\n  } catch (err) {\n    console.log(\"regexDataExtraction: regexString isn't a valid regular expression\");\n    regex = null;\n  } // matchNumber\n\n\n  if (matchNumber !== '*') {\n    matchNumber = parseInt(matchNumber);\n\n    if (isNaN(matchNumber)) {\n      console.log('regexDataExtraction: matchNumber needs to be an integer or *');\n      matchNumber = null;\n    }\n  } // group\n\n\n  group = parseInt(group);\n\n  if (isNaN(group)) {\n    console.log('regexDataExtraction: group needs to be an intereger');\n    group = null;\n  } // containerXpath\n  // set xpath to html element if blank\n\n\n  containerXpath = !containerXpath ? '//html' : containerXpath; // test if the element is on the page\n\n  const container = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath);\n\n  if (!container) {\n    console.log(`regexDataExtraction: Unable to find container element with xpath ${containerXpath}`);\n    containerXpath = null;\n  }\n\n  return [regex, matchNumber, group, containerXpath];\n};\nconst regexDataExtraction = function (regexString, matchNumber, group, containerXpath, removeDuplicates) {\n  // return if input isn't valid. input is invalid if any of the return values are false\n  var regex;\n  [regex, matchNumber, group, containerXpath] = validateRegexDataExtraction(regexString, matchNumber, group, containerXpath);\n  if ([regex, matchNumber, group, containerXpath].indexOf(null) !== -1) return [];\n  const containerElement = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](containerXpath);\n  const searchString = containerElement.outerHTML; // iterate through the matches until we get to the correct one\n\n  var count = 0;\n  const getAllMatches = matchNumber === '*';\n  var results = [];\n  var match;\n\n  while ((match = regex.exec(searchString)) !== null) {\n    // find the match if getting all matches or at correct match number\n    if (getAllMatches || count === matchNumber) {\n      let result = match[group]; // fail if match group doesn't exist\n\n      if (result === undefined) {\n        console.log('regexDataExtraction: group not found within match');\n        return [];\n      }\n\n      results.push(result);\n    } // increment count\n\n\n    count++; // stop if match number is less than count and we're not getting all the matches\n\n    if (!getAllMatches && matchNumber < count) break;\n  }\n\n  if (count < matchNumber) {\n    console.log('regexDataExtraction: Ran out of matches before getting to the input match number');\n  }\n\n  if (removeDuplicates) {\n    results = _utils__WEBPACK_IMPORTED_MODULE_1__[\"removeDuplicates\"](results);\n  }\n\n  return results.length === 1 ? results[0] : results;\n};\nconst staticValue = function (value) {\n  return value;\n};\n/**\n *  Takes an xpath for an element and clicks that element\n */\n\nconst click = function (xpath) {\n  const element = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](xpath);\n\n  if (!element) {\n    console.log(`click: Unable to find element with xpath ${xpath}`);\n  } else {\n    element.click();\n  }\n};\nconst attemptLogin = function (platformLogin, username, password) {\n  const {\n    usernameXpath,\n    passwordXpath\n  } = platformLogin;\n  const usernameInput = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](usernameXpath);\n\n  if (usernameInput === null) {\n    return false;\n  }\n\n  const passwordInput = _utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"](passwordXpath);\n\n  if (passwordInput === null) {\n    return false;\n  }\n\n  const event = new Event('change');\n  usernameInput.setAttribute('value', username);\n  usernameInput.dispatchEvent(event);\n  passwordInput.setAttribute('value', password);\n  usernameInput.dispatchEvent(event);\n  return true;\n};\nconsole.log('Loaded scraping');\n\n//# sourceURL=webpack:///./scraping.js?");

/***/ }),

/***/ "./scraping_interface.js":
/*!*******************************!*\
  !*** ./scraping_interface.js ***!
  \*******************************/
/*! exports provided: parsePluginMessage, scrapeGroup */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"parsePluginMessage\", function() { return parsePluginMessage; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrapeGroup\", function() { return scrapeGroup; });\n/* harmony import */ var _scraping__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./scraping */ \"./scraping.js\");\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./utils */ \"./utils.js\");\n/* harmony import */ var scrape_actions_NumbersOnlyPagination__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! scrape_actions/NumbersOnlyPagination */ \"./scrape_actions/NumbersOnlyPagination.js\");\n\n\n\nconst parsePluginMessage = async function (message) {\n  /***\n  *Called when the plugin is testing scraping functionality. Sends the message received on to the revelant\n  *test scraping functions.\n  */\n  console.log('Parsing plugin message ' + message.command); // declare variables used more than once\n\n  var result, regex, group, containerXpath, removeDuplicates;\n\n  switch (message.command) {\n    case 'clickGalleryExtract':\n      var {\n        galleryXpath,\n        imageXpath,\n        waitTime\n      } = message;\n      result = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"clickGalleryExtract\"](galleryXpath, imageXpath, waitTime);\n      return Promise.resolve(result);\n\n    case 'extractContainedImages':\n      var sources = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"extractContainedImages\"](message.payload);\n      return Promise.resolve({\n        sources: sources\n      });\n\n    case 'paginateByFormatString':\n      var scrapedUrls = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"pagination\"](4, message.payload.containerXpath, message.payload.formatString, message.payload.urlRegex, message.payload.xpathOfNextButton);\n      return Promise.resolve({\n        urls: scrapedUrls\n      });\n\n    case 'runXpathDataExtraction':\n      var extractedData = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"xpathDataExtraction\"](message.elementXpath, message.selectedOption, message.targetAttribute, message.processorFunction);\n      return Promise.resolve(extractedData);\n\n    case 'runRegexUrlExtraction':\n      var extractedUrls = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"regexUrlExtraction\"](message.containerXpath, message.urlRegex, message.infiniteScroll);\n      return Promise.resolve(extractedUrls);\n\n    case 'runRegexUrlProcessor':\n      regex = message.regex;\n      result = _scraping__WEBPACK_IMPORTED_MODULE_0__[\"regexUrlProcessor\"](regex);\n      return Promise.resolve(result);\n\n    case 'runClickRegexExtractStringReplace':\n      var buttonXpath, replaceSource, replaceTarget;\n      ({\n        buttonXpath,\n        containerXpath,\n        regex,\n        group,\n        replaceSource,\n        replaceTarget,\n        removeDuplicates\n      } = message);\n\n      try {\n        result = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"clickRegexExtractStringReplace\"](buttonXpath, containerXpath, regex, group, replaceSource, replaceTarget, removeDuplicates);\n      } catch (err) {\n        console.log(err);\n      }\n\n      return Promise.resolve(result);\n\n    case 'runSimpleImageExtraction':\n      var extractedSources = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"simpleImageExtraction\"](message.containerXpath, message.sourceRegex);\n      return Promise.resolve(extractedSources);\n\n    case 'runRegexDataExtraction':\n      var matchNumber;\n      ({\n        regex,\n        matchNumber,\n        group,\n        containerXpath,\n        removeDuplicates\n      } = message);\n\n      try {\n        result = _scraping__WEBPACK_IMPORTED_MODULE_0__[\"regexDataExtraction\"](regex, matchNumber, group, containerXpath, removeDuplicates);\n      } catch (err) {\n        console.log(err);\n      }\n\n      console.log(result);\n      return Promise.resolve(result);\n\n    case 'LoadContentAndScroll':\n      result = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"loadContentAndScroll\"](message.payload.loadContentXpath, message.payload.containerXpath, message.payload.regex);\n      return Promise.resolve(result);\n\n    case 'runStaticValue':\n      result = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"staticValue\"](message.staticValue);\n      return Promise.resolve(result);\n\n    case 'runClick':\n      result = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"click\"](message.xpath);\n      return Promise.resolve(result);\n\n    case 'runNumbersOnlyPagination':\n      var NumbersOnlyPaginationAction = new scrape_actions_NumbersOnlyPagination__WEBPACK_IMPORTED_MODULE_2__[\"NumbersOnlyPagination\"](message);\n      result = await NumbersOnlyPaginationAction.scrape();\n      return Promise.resolve(result);\n\n    case 'testTransformFunction':\n      // simulate a normal scrape\n      const testScrapeData = {\n        testField: message.testData.input\n      };\n      const testTransformConfig = {\n        testResult: message.testData\n      };\n      testTransformConfig.testResult.sourceField = 'testField';\n      testTransformConfig.testResult.order = 0;\n      result = _scraping__WEBPACK_IMPORTED_MODULE_0__[\"processData\"](testScrapeData, testTransformConfig, {});\n      return Promise.resolve(result.testResult);\n\n    case 'inputText':\n      var {\n        inputXpath\n      } = message;\n      var text = 'test text';\n      result = Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"enterTextIntoInput\"])(inputXpath, text);\n      return Promise.resolve(result);\n\n    case 'testLoginValidation':\n      var elem = Object(_utils__WEBPACK_IMPORTED_MODULE_1__[\"getElementByXpath\"])(message.xpath);\n      result = elem ? 'Found Element' : 'Could not find elemenet';\n      return Promise.resolve(result);\n  }\n};\nconst scrapeGroup = async (groupName, config, platformMetadata) => {\n  // scrape the group\n  const pageConfig = config[groupName].itemScrapes;\n  const transformConfig = config[groupName].transformFunctions;\n  var scrapedData = {}; // perform any scrape actions, if they exist\n\n  if (pageConfig != null) {\n    scrapedData = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"scrapePage\"](pageConfig, platformMetadata);\n  } // perform any transformations if they exist\n\n\n  if (transformConfig != null) {\n    scrapedData = _scraping__WEBPACK_IMPORTED_MODULE_0__[\"processData\"](scrapedData, transformConfig, platformMetadata);\n  }\n\n  return scrapedData;\n};\n/**\n*  Takes an instruction to scrape an entire page, e.g. index or item page,\n*  and calls the relevant scrape functions.\n*/\n\nwindow.parseScrapeInstruction = async function (groupName, scraperConfig, platformMetadata, isIframe = false) {\n  console.log('Scraper config entered as ' + JSON.stringify(scraperConfig)); // use the iframe group if it's an iframe scrape\n\n  if (isIframe) {\n    groupName += '_iframe';\n  } // perform the scrape for the given tab\n\n\n  const scrapedData = await scrapeGroup(groupName, scraperConfig, platformMetadata);\n  window.results = scrapedData;\n};\n\nwindow.parseValidationInstruction = async function (groupName, scraperConfig) {\n  console.log('Scraper config entered as ' + JSON.stringify(scraperConfig));\n  const pageConfig = scraperConfig[groupName].validation;\n  window.validationResults = await _scraping__WEBPACK_IMPORTED_MODULE_0__[\"validatePage\"](pageConfig);\n};\n/**\n * This method runs a test config.\n *\n * Params:\n *   - baseUrl: String of the base url to use for getting the config\n *   e.g. dev-toms.aws.devicp.eu:8000\n *   - testName: String name of the test e.g. test_basic_scrape\n *\n */\n\n\nwindow.testConfig = async function (rawScraperConfig) {\n  const groupName = 'testing'; // perform the scrape for the given tab\n\n  const scraperConfig = JSON.parse(rawScraperConfig);\n  const scrapedData = await scrapeGroup(groupName, scraperConfig, {});\n  return scrapedData;\n};\n\nwindow.testValidation = async function (rawScraperConfig) {\n  const scraperConfig = JSON.parse(rawScraperConfig);\n  const testConfig = scraperConfig.testing.validation;\n  return _scraping__WEBPACK_IMPORTED_MODULE_0__[\"validatePage\"](testConfig);\n};\n\nconsole.log('Loaded scraping_interface');\n\n//# sourceURL=webpack:///./scraping_interface.js?");

/***/ }),

/***/ "./transform_functions/RegexExtraction.js":
/*!************************************************!*\
  !*** ./transform_functions/RegexExtraction.js ***!
  \************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var validation__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! validation */ \"./validation.js\");\n/* harmony import */ var utils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! utils */ \"./utils.js\");\n\n\n\nclass RegexExtraction {\n  constructor(config, platformMetadata) {\n    this.config = config;\n    this.errors = {};\n  }\n\n  checkValid() {\n    var isValid = true;\n\n    try {\n      // must be a valid regex\n      this.regex = Object(validation__WEBPACK_IMPORTED_MODULE_0__[\"validateRegex\"])(this.config.pattern, this.config.flags);\n    } catch (err) {\n      this.errors.regex = err.message;\n      isValid = false;\n    } // must be a list of integers\n\n\n    try {\n      this.groupCombiningOrder = Object(validation__WEBPACK_IMPORTED_MODULE_0__[\"validateArray\"])(this.config.groupCombiningOrder, validation__WEBPACK_IMPORTED_MODULE_0__[\"confirmInteger\"]);\n    } catch (err) {\n      this.errors.groupCombiningOrder = err.message;\n      isValid = false;\n    } // must be a single character\n\n\n    try {\n      this.joinCharacter = Object(validation__WEBPACK_IMPORTED_MODULE_0__[\"validateCharacter\"])(this.config.joinCharacter, true);\n    } catch (err) {\n      this.errors.joinCharacter = err.message;\n      isValid = false;\n    }\n\n    this.isValid = isValid;\n    return isValid;\n  }\n\n  transform(input) {\n    return utils__WEBPACK_IMPORTED_MODULE_1__[\"combineRegexResult\"](input, this.regex, this.groupCombiningOrder, this.joinCharacter);\n  }\n\n} // name needs to be explicitly defined as .name will change if code is minified\n\n\nRegexExtraction.functionName = 'RegexExtraction'; // used to check that all attributes are present before running validation\n\nRegexExtraction.configAttributes = ['pattern', 'flags', 'groupCombiningOrder', 'joinCharacter'];\n/* harmony default export */ __webpack_exports__[\"default\"] = (RegexExtraction);\n\n//# sourceURL=webpack:///./transform_functions/RegexExtraction.js?");

/***/ }),

/***/ "./utils.js":
/*!******************!*\
  !*** ./utils.js ***!
  \******************/
/*! exports provided: getElementByXpath, getElementsByXpath, getElementByTagAndText, getElementTextByXpath, getValueOfElementAttribute, sleep, removeDuplicates, arrayStringReplace, globalRegexWithGroup, simplifyUrl, filterUrl, getAttributeRecursively, clickElement, checkStringContainsTemplate, intersection, getFunctionParameterNames, logFunctionCall, scrollToBottom, scrollToHeight, scrapeError, combineRegexResult, enterTextIntoInput */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getElementByXpath\", function() { return getElementByXpath; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getElementsByXpath\", function() { return getElementsByXpath; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getElementByTagAndText\", function() { return getElementByTagAndText; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getElementTextByXpath\", function() { return getElementTextByXpath; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getValueOfElementAttribute\", function() { return getValueOfElementAttribute; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"sleep\", function() { return sleep; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"removeDuplicates\", function() { return removeDuplicates; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"arrayStringReplace\", function() { return arrayStringReplace; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"globalRegexWithGroup\", function() { return globalRegexWithGroup; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"simplifyUrl\", function() { return simplifyUrl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"filterUrl\", function() { return filterUrl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getAttributeRecursively\", function() { return getAttributeRecursively; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"clickElement\", function() { return clickElement; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"checkStringContainsTemplate\", function() { return checkStringContainsTemplate; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"intersection\", function() { return intersection; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getFunctionParameterNames\", function() { return getFunctionParameterNames; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logFunctionCall\", function() { return logFunctionCall; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrollToBottom\", function() { return scrollToBottom; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrollToHeight\", function() { return scrollToHeight; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"scrapeError\", function() { return scrapeError; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"combineRegexResult\", function() { return combineRegexResult; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enterTextIntoInput\", function() { return enterTextIntoInput; });\n/* harmony import */ var _utils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./utils */ \"./utils.js\");\n/* harmony import */ var exceptions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! exceptions */ \"./exceptions.js\");\n/**\n* utility functions\n*/\n\n\nfunction getElementByXpath(path) {\n  const returnVal = document.evaluate(path, document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;\n  return returnVal;\n}\nfunction getElementsByXpath(path) {\n  const nodeList = [];\n  const result = document.evaluate(path, document, null, XPathResult.ANY_TYPE, null);\n  var node;\n\n  while (node = result.iterateNext()) {\n    nodeList.push(node);\n  }\n\n  return nodeList;\n}\nfunction getElementByTagAndText(tag, text) {\n  const tags = document.getElementsByTagName(tag);\n  var found;\n\n  for (var i = 0; i < tags.length; i++) {\n    if (tags[i].href.includes(text)) {\n      found = tags[i];\n      break;\n    }\n  }\n\n  return found;\n}\nfunction getElementTextByXpath(path) {\n  try {\n    const element = _utils__WEBPACK_IMPORTED_MODULE_0__[\"getElementByXpath\"](path);\n    return element.textContent;\n  } catch (err) {\n    return null;\n  }\n}\nfunction getValueOfElementAttribute(path, attributeName) {\n  try {\n    const element = _utils__WEBPACK_IMPORTED_MODULE_0__[\"getElementByXpath\"](path);\n    return element.getAttribute(attributeName);\n  } catch (err) {\n    return null;\n  }\n}\nfunction sleep(milliseconds) {\n  return new Promise(resolve => setTimeout(resolve, milliseconds));\n}\n/*\n * This function takes a list of hashable values and removes duplicates\n *\n * arr: Array\n */\n\nfunction removeDuplicates(arr) {\n  return [...new Set(arr)];\n}\n/*\n * This function takes a list of strings and runs a string replace on each entry\n *\n * arr: Array\n * toReplace, replacement: String\n */\n\nfunction arrayStringReplace(arr, toReplace, replacement) {\n  var results = [];\n\n  for (var item of arr) {\n    var processedItem = item.replace(toReplace, replacement);\n    results.push(processedItem);\n  }\n\n  return results;\n}\nfunction globalRegexWithGroup(regexObj, searchString, group) {\n  /*\n  * This method runs a global regex search on a string returning a list of\n  * results using a given group\n  *\n  * regexObj: RegExp()\n  * searchString: String\n  * group: Int\n  */\n  var results = [];\n  var result;\n\n  if (!regexObj.global) {\n    console.log('regexObj has no global flag, adding global flag');\n    regexObj = new RegExp(regexObj, regexObj.flags + 'g');\n  }\n\n  while ((result = regexObj.exec(searchString)) !== null) {\n    results.push(result[group]);\n  }\n\n  return results;\n}\nfunction simplifyUrl(url) {\n  // Optional URL simplification function\n  return url;\n}\nfunction filterUrl(url, urlRegexString) {\n  try {\n    return RegExp(urlRegexString).test(url);\n  } catch (err) {\n    console.log('Error in filterUrl');\n    return false;\n  }\n}\nfunction getAttributeRecursively(element, attribute) {\n  /**\n  * Recursively get the href from container and any elements below it\n  */\n  var attributes = [];\n\n  if (element[attribute]) {\n    attributes.push(element[attribute]);\n  }\n\n  for (var child of element.children) {\n    attributes.push(...getAttributeRecursively(child, attribute));\n  }\n\n  return attributes;\n}\nfunction clickElement(elementXpath) {\n  let element = _utils__WEBPACK_IMPORTED_MODULE_0__[\"getElementByXpath\"](elementXpath);\n  element.click();\n}\nfunction checkStringContainsTemplate(string, template) {\n  return string.includes(template);\n}\nfunction intersection(a1, a2) {\n  /**\n  * Intersection of two arrays\n  */\n  var s1 = new Set(a1);\n  var s2 = new Set(a2);\n  return Array.from(new Set([...s1].filter(x => s2.has(x))));\n}\nfunction getFunctionParameterNames(func) {\n  /**\n   * Given a function, returns array containing the names of the parameters in that function\n   */\n  const STRIP_COMMENTS = /((\\/\\/.*$)|(\\/\\*[\\s\\S]*?\\*\\/))/mg;\n  const ARGUMENT_NAMES = /([^\\s,]+)/g;\n  var fnStr = func.toString().replace(STRIP_COMMENTS, '');\n  var result = fnStr.slice(fnStr.indexOf('(') + 1, fnStr.indexOf(')')).match(ARGUMENT_NAMES);\n\n  if (result === null) {\n    result = [];\n  }\n\n  return result;\n}\nfunction logFunctionCall(func, args) {\n  /**\n   * Given a function, this function logs out the function call with the argument\n   * e.g. \"my_func(arg1=1, arg2=2, arg3=3)\"\n   */\n  const functionParamNames = getFunctionParameterNames(func);\n  var parameterString = ''; // handle all known parameters\n\n  for (var i = 0; i < functionParamNames.length; ++i) {\n    parameterString += `${functionParamNames[i]}=${args[i]}, `;\n  } // handle any unknown parameters\n\n\n  for (i = functionParamNames.length; i < args.length; ++i) {\n    parameterString += `${args[i]}, `;\n  } // remove trailing comma and space\n\n\n  parameterString = parameterString.slice(0, -2);\n  var logString = `${func.name}(${parameterString})`;\n  console.log(logString);\n}\nfunction scrollToBottom() {\n  window.scrollTo(0, document.body.scrollHeight);\n}\nfunction scrollToHeight(height) {\n  window.scrollTo({\n    left: 0,\n    top: height,\n    behavior: 'smooth'\n  });\n}\nfunction scrapeError(message) {\n  const exception = {\n    name: 'Scrape Error',\n    message: message,\n    toString: function () {\n      return `${this.name}: ${this.message}`;\n    }\n  };\n  exception.toString.bind(exception);\n  return exception;\n}\n/**\n * Given a string and a regex object, extract the specified groups and join\n * them using the join character\n */\n\nfunction combineRegexResult(input, regex, combiningOrder, joinCharacter) {\n  // extract the groups\n  const result = regex.exec(input);\n\n  if (result === null) {\n    const errorMessage = 'Regex failed to return result';\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"TransformError\"](errorMessage);\n  } // order the groups\n\n\n  const orderedGroups = [];\n\n  for (var index of combiningOrder) {\n    var group = result[index];\n\n    if (group === undefined) {\n      const errorMessage = 'Regex group does not exist';\n      throw new exceptions__WEBPACK_IMPORTED_MODULE_1__[\"TransformError\"](errorMessage);\n    }\n\n    orderedGroups.push(result[index]);\n  } // join the groups\n\n\n  const joinedGroups = orderedGroups.join(joinCharacter);\n  return joinedGroups;\n}\nfunction enterTextIntoInput(inputXpath, text) {\n  const elem = getElementByXpath(inputXpath);\n\n  if (!elem) {\n    return;\n  }\n\n  const event = new Event('change');\n  elem.setAttribute('value', text);\n  elem.dispatchEvent(event);\n}\n\n//# sourceURL=webpack:///./utils.js?");

/***/ }),

/***/ "./validation.js":
/*!***********************!*\
  !*** ./validation.js ***!
  \***********************/
/*! exports provided: checkAttributes, validateRegex, stringToInt, confirmInteger, validateArray, validateCharacter */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"checkAttributes\", function() { return checkAttributes; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateRegex\", function() { return validateRegex; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stringToInt\", function() { return stringToInt; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"confirmInteger\", function() { return confirmInteger; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateArray\", function() { return validateArray; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"validateCharacter\", function() { return validateCharacter; });\n/* harmony import */ var exceptions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! exceptions */ \"./exceptions.js\");\n\n/**\n *  Takes an array of strings and an object.\n *  Checks each of the strings is an attribute on the object\n */\n\nconst checkAttributes = (attributes, object) => {\n  const missingAttributes = [];\n\n  for (var attribute of attributes) {\n    if (!(attribute in object)) {\n      missingAttributes.push(attribute);\n    }\n  }\n\n  return missingAttributes;\n};\n/**\n * Validates that a pattern-flags pair can be used to create a valid RegExp object\n */\n\nconst validateRegex = (pattern, flags = '') => {\n  try {\n    RegExp(pattern);\n  } catch (err) {\n    const errorMessage = `Invalid regex pattern ${pattern} - ${err.message}`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  } // check flags\n\n\n  try {\n    RegExp('', flags);\n  } catch (err) {\n    const errorMessage = `Invalid regex flags ${flags} - ${err.message}`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n\n  return RegExp(pattern, flags);\n};\n/**\n * Takes a string and returns true of false based on whether it\n * represents an integer\n */\n\nconst isStringInteger = input => {\n  // TODO unit test\n  // TODO figure out how to test functions which aren't exported\n  // check is integer\n  if (Number.isInteger(input)) return true; // check if string represents an integer\n\n  const parsedInput = parseInt(input);\n  return parsedInput.toString() === input && !isNaN(parsedInput);\n};\n\nconst stringToInt = string => {\n  if (!isStringInteger(string)) {\n    const errorMessage = `Could not parse ${string} to integer`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n\n  return parseInt(string);\n};\n/**\n *  Raises exception if input ins't integer. Otherwise returns input\n */\n\nconst confirmInteger = input => {\n  if (!Number.isInteger(input)) {\n    const errorMessage = `${input} is not an integer`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n\n  return input;\n};\n/**\n * Takes an array and a validation function and applies the validation function to every item in the array\n */\n\nconst validateArray = (arrayString, validationFunction) => {\n  // check can be parsed\n  try {\n    var array = JSON.parse(arrayString);\n  } catch (err) {\n    const errorMessage = `Unable to parse '${arrayString}' as JSON`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  } // check parse value is an array\n\n\n  if (!Array.isArray(array)) {\n    const errorMessage = `Parsed value of ${arrayString} is not an array`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n\n  try {\n    return array.map(validationFunction);\n  } catch (err) {\n    const errorMessage = `Failed to validate array [${array}] - ${err.message}`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n};\n\nconst validateLength = (input, minLength, maxLength) => {\n  // TODO unit test\n  const inputLength = input.length;\n\n  if (inputLength === undefined) {\n    const errorMessage = `Cannot determine length of ${input}`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n\n  if (inputLength < minLength | inputLength > maxLength) {\n    const errorMessage = `Length of ${input} is not within the range [${minLength}, ${maxLength}]`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n};\n/**\n * Checks that input string is of length 1\n */\n\n\nconst validateCharacter = (input, allowEmpty = false) => {\n  const minLength = allowEmpty ? 0 : 1;\n  const maxLength = 1;\n\n  try {\n    // throws exception if there is an issue\n    validateLength(input, minLength, maxLength);\n    return input;\n  } catch (err) {\n    const errorMessage = `Input '${input}' is not a single character`;\n    throw new exceptions__WEBPACK_IMPORTED_MODULE_0__[\"ValidationError\"](errorMessage);\n  }\n};\n\n//# sourceURL=webpack:///./validation.js?");

/***/ })

/******/ });